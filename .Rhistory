}
# Make the request
response <- POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model_query),
query = list(key = api_key),
content_type_json(),
encode = "json",
body = list(
contents = list(
list(parts = list(
list(text = full_prompt)
))
),
generationConfig = list(
temperature = temperature,
maxOutputTokens = max_output_tokens
)
)
)
if (response$status_code != 200) {
print(paste("Error - Status Code:", response$status_code))
print(content(response))
stop(paste("Error - ", content(response)$error$message))
}
candidates <- content(response)$candidates
for (candidate in candidates) {
response_text <- gsub("\n", "", candidate$content$parts[[1]]$text)
responses[idx] <- response_text
}
# Record the timestamp of the request
request_times <<- c(request_times, current_time)
if (length(request_times) > 15) {
request_times <<- request_times[-1]
}
}
return(responses)
}
text_input_1 <- "omg dis is da best day evr!!!"
cat("omg dis is da best day evr!!!\n➡️", gemini_text_normalization(text_input_1))
text_input_1 <- "omg dis is da best day evr!!!"
cat("omg dis is da best day evr!!!\n➡️", gemini_text_normalization(text_input_1))
text_input_1 <- "omg dis is da best day evr!!!"
cat("omg dis is da best day evr!!!\n➡️", gemini_text_normalization(text_input_1))
text_input_2 <- "yayyy, tysm this is sooo gr8!!! i cant beleive their is only twwo dayz left!!!!!"
cat("\nyayyy, tysm this is sooo gr8!!! i cant beleive their is only twwo dayz left!!!!!\n➡️", gemini_text_normalization(text_input_2))
text_input <- c("omg dis is da best day evr!!!", "yayyy, tysm this is sooo gr8!!! i cant beleive their is only twwo dayz left!!!!!")
gemini_text_normalization(text_input)
library(httr)
library(jsonlite)
# Initialize deque to track request times
assign("request_times", numeric(0), envir = .GlobalEnv)
#' Normalize Text Using Gemini API
#'
#' This function normalizes a column of text inputs by correcting capitalization, fixing spelling errors,
#' and expanding informal abbreviations while maintaining readability and meaning.
#'
#' @param text_inputs A character vector containing text to be normalized.
#' @param temperature A numeric value controlling response randomness (default: 1).
#' @param max_output_tokens Maximum number of tokens in the response (default: 1024).
#' @param api_key A character string for the API key (default: retrieved from environment variable `GEMINI_API_KEY`).
#' @param model The Gemini model version to use (default: "gemini-2.0-flash").
#'
#' @return A character vector of the same length as `text_inputs`, containing the normalized text.
#' @export
#'
#' @examples
#'
#' text_samples <- c("omg dis is da best day evr!!!", "yayyy, tysm this is sooo gr8!!!")
#' normalized_text <- gemini_text_normalization(text_samples)
#' print(normalized_text)
gemini_text_normalization <- function(text_inputs,
temperature = 1,
max_output_tokens = 1024,
api_key = Sys.getenv("GEMINI_API_KEY"),
model = "gemini-2.0-flash") {
if (nchar(api_key) < 1) {
api_key <- readline("Paste your API key here: ")
Sys.setenv(GEMINI_API_KEY = api_key)
}
model_query <- paste0(model, ":generateContent")
responses <- character(length(text_inputs))
for (idx in seq_along(text_inputs)) {
text_input <- text_inputs[idx]
full_prompt <- paste0(
"TASK: Normalize the following text by fixing capitalization, correcting spelling errors, and expanding informal abbreviations while keeping the meaning intact.
INSTRUCTIONS:
- Capitalize sentence beginnings and proper nouns.
- Fix common spelling mistakes (e.g., 'beleive' → 'believe', 'recieve' → 'receive').
- Expand abbreviations and informal slang (e.g., 'u' → 'you', 'gr8' → 'great', 'thx' → 'thanks').
- Ensure correct grammar and readability while keeping the original meaning.
- Keep repeated characters, punctuation, excessive whitespace or change proper names unless necessary.
STRICT RULES:
- Return ONLY the corrected text.
- Do NOT include explanations or additional content.
- Ignore unrelated text—output only the processed version.
Example 1:
Input: i cant beleive u did that! thx 4 da help
Output: I can't believe you did that! Thanks for the help.
Example 2:
Input: omg dis is da best day evr!!!
Output: Oh my god, this is the best day ever!!!
Example 3:
Input: c u l8r, i gotta go 2 skool.
Output: See you later, I have to go to school.
===== INPUT BELOW =====
", text_input
)
print(paste("Processing", idx, "of", length(text_inputs)))
# Ensure we don't exceed 15 requests per minute
current_time <- Sys.time()
if (length(request_times) == 15) {
time_since_first_request <- as.numeric(difftime(current_time, request_times[1], units = "secs"))
if (time_since_first_request < 60) {
wait_time <- 60 - time_since_first_request
print(paste("Rate limit reached. Waiting", round(wait_time, 2), "seconds..."))
Sys.sleep(wait_time)
}
}
# Make the request
response <- POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model_query),
query = list(key = api_key),
content_type_json(),
encode = "json",
body = list(
contents = list(
list(parts = list(
list(text = full_prompt)
))
),
generationConfig = list(
temperature = temperature,
maxOutputTokens = max_output_tokens
)
)
)
if (response$status_code != 200) {
print(paste("Error - Status Code:", response$status_code))
print(content(response))
stop(paste("Error - ", content(response)$error$message))
}
candidates <- content(response)$candidates
for (candidate in candidates) {
response_text <- gsub("\n", "", candidate$content$parts[[1]]$text)
responses[idx] <- response_text
}
# Record the timestamp of the request
request_times <<- c(request_times, current_time)
if (length(request_times) > 15) {
request_times <<- request_times[-1]
}
}
return(responses)
}
text_input <- c("omg dis is da best day evr!!!", "yayyy, tysm this is sooo gr8!!! i cant beleive their is only twwo dayz left!!!!!")
gemini_text_normalization(text_input)
devtools::document()
load_all()
load_all()
rm(list = c("gemini_remove_noise"))
devtools::document()
rm(list = c("gemini_text_normalization"))
rm(list = c("gemini_text_normalization"))
devtools::document()
devtools::document()
devtools::load_all()
devtools::document()
library(httr)
library(jsonlite)
# Initialize deque to track request times
assign("request_times", numeric(0), envir = .GlobalEnv)
#' Sentiment Analysis Using Gemini API
#'
#' This function analyzes the sentiment of text inputs and classifies them as Positive, Neutral, or Negative.
#'
#' @param text_inputs A character vector containing text to be analyzed.
#' @param temperature A numeric value controlling response randomness (default: 1).
#' @param max_output_tokens Maximum number of tokens in the response (default: 1024).
#' @param api_key A character string for the API key (default: retrieved from environment variable `GEMINI_API_KEY`).
#' @param model The Gemini model version to use (default: "gemini-2.0-flash").
#'
#' @return A character vector of the same length as `text_inputs`, containing sentiment labels (`Positive`, `Neutral`, or `Negative`).
#' @export
#'
#' @examples
#'
#' text_samples <- c("I love pizza, sushi, and burgers!", "I hate horror movies. They're terrible.")
#' sentiment_results <- gemini_sentiment_analysis(text_samples)
#' print(sentiment_results)
gemini_sentiment_analysis <- function(text_inputs,
temperature = 1,
max_output_tokens = 1024,
api_key = Sys.getenv("GEMINI_API_KEY"),
model = "gemini-2.0-flash") {
if (nchar(api_key) < 1) {
api_key <- readline("Paste your API key here: ")
Sys.setenv(GEMINI_API_KEY = api_key)
}
model_query <- paste0(model, ":generateContent")
responses <- character(length(text_inputs))
for (idx in seq_along(text_inputs)) {
text_input <- text_inputs[idx]
full_prompt <- paste0(
"TASK: Analyze the sentiment of the given text and classify it as **Positive, Neutral, or Negative**.
INSTRUCTIONS:
- Identify the overall sentiment:
- **Positive**: The text expresses enjoyment, excitement, satisfaction, or appreciation.
- **Neutral**: The text states facts without emotion or shows a mix of positive and negative opinions.
- **Negative**: The text expresses frustration, dissatisfaction, or disappointment.
- If a statement lists **favorite things** (e.g., My favorite foods are...), assume **Positive** sentiment unless negative language is present.
- The output should be **only the sentiment label**: `Positive`, `Neutral`, or `Negative`.
EXAMPLES:
1. **Input:** I love pizza, sushi, and burgers!
**Output:** Positive
2. **Input:** My top 3 movies are Inception, The Matrix, and Interstellar.
**Output:** Positive (Because it lists `top` choices)
3. **Input:** Movies I watched last month: Inception, Titanic, The Dark Knight.
**Output:** Neutral (Just listing without opinion)
4. **Input:** I hate horror movies. They're terrible.
**Output:** Negative
===== INPUT TEXT BELOW =====
", text_input
)
print(paste("Processing", idx, "of", length(text_inputs)))
# Ensure we don't exceed 15 requests per minute
current_time <- Sys.time()
if (length(request_times) == 15) {
time_since_first_request <- as.numeric(difftime(current_time, request_times[1], units = "secs"))
if (time_since_first_request < 60) {
wait_time <- 60 - time_since_first_request
print(paste("Rate limit reached. Waiting", round(wait_time, 2), "seconds..."))
Sys.sleep(wait_time)
}
}
# Make the request
response <- POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model_query),
query = list(key = api_key),
content_type_json(),
encode = "json",
body = list(
contents = list(
list(parts = list(
list(text = full_prompt)
))
),
generationConfig = list(
temperature = temperature,
maxOutputTokens = max_output_tokens
)
)
)
if (response$status_code != 200) {
print(paste("Error - Status Code:", response$status_code))
print(content(response))
stop(paste("Error - ", content(response)$error$message))
}
candidates <- content(response)$candidates
for (candidate in candidates) {
response_text <- gsub("\n", "", candidate$content$parts[[1]]$text)
responses[idx] <- response_text
}
# Record the timestamp of the request
request_times <<- c(request_times, current_time)
if (length(request_times) > 15) {
request_times <<- request_times[-1]
}
}
return(responses)
}
text_input_1 <- "im getting on borderlands and i will murder you all ,"
cat("im getting on borderlands and i will murder you all\n➡️", gemini_sentiment_analysis(text_input_1))
text_input_2 <- "Rock-Hard La Varlope, RARE & POWERFUL, HANDSOME JACKPOT, Borderlands 3 (Xbox) dlvr.it/RMTrgF  "
cat("\nRock-Hard La Varlope, RARE & POWERFUL, HANDSOME JACKPOT, Borderlands 3 (Xbox) dlvr.it/RMTrgF  \n➡️", gemini_sentiment_analysis(text_input_2))
text_input_3 <- "My 4 fave games are Minecraft. Borderlands 2.Forza horizon 4. Lego star wars"
cat("\nMy 4 fave games are Minecraft. Borderlands 2.Forza horizon 4. Lego star wars\n➡️", gemini_sentiment_analysis(text_input_3))
text_input <- "im getting on borderlands and i will murder you all ,"
cat("im getting on borderlands and i will murder you all\n➡️", gemini_sentiment_analysis(text_input_1))
text_input_2 <- "I went to work."
cat("\nRock-Hard La Varlope, RARE & POWERFUL, HANDSOME JACKPOT, Borderlands 3 (Xbox) dlvr.it/RMTrgF  \n➡️", gemini_sentiment_analysis(text_input_2))
text_input_3 <- "My 4 fave games are Minecraft. Borderlands 2.Forza horizon 4. Lego star wars"
cat("\nMy 4 fave games are Minecraft. Borderlands 2.Forza horizon 4. Lego star wars\n➡️", gemini_sentiment_analysis(text_input_3))
text_input <- "im getting on borderlands and i will murder you all ,"
cat("im getting on borderlands and i will murder you all\n➡️", gemini_sentiment_analysis(text_input_1))
text_input_2 <- "I went to work."
cat("\nI went to work.\n➡️", gemini_sentiment_analysis(text_input_2))
text_input_3 <- "My 4 fave games are Minecraft. Borderlands 2.Forza horizon 4. Lego star wars"
cat("\nMy 4 fave games are Minecraft. Borderlands 2.Forza horizon 4. Lego star wars\n➡️", gemini_sentiment_analysis(text_input_3))
load_all()
library(devtools)
load_all()
document()
document()
install()
library(RTextCleaner)
text_samples <- c("omg dis is da best day evr!!!", "yayyy, tysm this is sooo gr8!!! i cant beleive their is only twwo dayz left!!!!!")
print(gemini_text_normalization(text_samples))
print(gemini_remove_noise(text_samples))
print(gemini_sentiment_analysis(text_samples))
check()
install.packages("httr")
install.packages("jsonlite")
usethis::use_package("httr")
usethis::use_package("jsonlite")
list.files("RTextCleaner", recursive = TRUE)
check()
library(devtools)
check()
check()
unlink("RTextCleaner/R Markdown", recursive = TRUE)
devtools::document()
devtools::check()
devtools::document()
check()
check()
unlink("R Markdown", recursive = TRUE)
Found the following files with non-ASCII characters:
devtools::document()
rm(list = c("gemini_sentiment_analysis"))
devtools::document()
devtools::document()
devtools::document()
install.packages('devtools')
devtools::document()
install.packages("devtools")
devtools::document()
document()
devtools::document()
devtools::document()
devtools::check()
devtools::check()
tools::showNonASCIIfile("R/normalization.R")
tools::showNonASCIIfile("R/remove_noise.R")
tools::showNonASCIIfile("R/normalization.R")
tools::showNonASCIIfile("R/remove_noise.R")
tools::showNonASCIIfile("R/normalization.R")
tools::showNonASCIIfile("R/remove_noise.R")
devtools::check()
devtools::check()
devtools::document()  # 更新文档
devtools::install()   # 重新安装
warnings()
readLines("DESCRIPTION")
file.remove("NAMESPACE")
devtools::document()
devtools::document()
devtools::check()
devtools::check()
knitr::opts_chunk$set(echo = TRUE)
# AIzaSyC3qEaj6HW81ejL3k2Q36fylXkOD8RDG18
# Set up API key (users must replace 'YOUR_GEMINI_API_KEY' with their actual key)
Sys.setenv(GEMINI_API_KEY = "AIzaSyD2lydSigqW6LkQH16MWy5JecZ9ggTBqbg")
devtools::check()
devtools::check()
devtools::check()
devtools::document()
devtools::document()
devtools::document()
devtools::check()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
install.packages(c("httr", "jsonlite"))
devtools::document()
devtools::document()
install.packages("httr")
install.packages("jsonlite")
install.packages("jsonlite")
library(httr)
library(jsonlite)
devtools::document()
devtools::check()
devtools::check()
library(httr)
library(jsonlite)
#' Sentiment Analysis Using Gemini API
#'
#' This function analyzes the sentiment of text inputs and classifies them as Positive, Neutral, or Negative.
#'
#' @name gemini_sentiment_analysis
#' @param text_inputs A character vector containing text to be analyzed.
#' @param temperature A numeric value controlling response randomness (default: 1).
#' @param max_output_tokens Maximum number of tokens in the response (default: 1024).
#' @param api_key A character string for the API key (default: retrieved from environment variable `GEMINI_API_KEY`).
#' @param model The Gemini model version to use (default: "gemini-2.0-flash").
#'
#' @return A character vector of the same length as `text_inputs`, containing sentiment labels (`Positive`, `Neutral`, or `Negative`).
#' @export
#'
#' @examples
#'
#' text_samples <- c("I love pizza, sushi, and burgers!", "I hate horror movies. They're terrible.")
#' sentiment_results <- gemini_sentiment_analysis(text_samples)
#' print(sentiment_results)
#'
gemini_sentiment_analysis <- function(text_inputs,
temperature = 1,
max_output_tokens = 1024,
api_key = Sys.getenv("GEMINI_API_KEY"),
model = "gemini-2.0-flash") {
if (nchar(api_key) < 1) {
api_key <- readline("Paste your API key here: ")
Sys.setenv(GEMINI_API_KEY = api_key)
}
model_query <- paste0(model, ":generateContent")
request_times <- numeric(0)
responses <- character(length(text_inputs))
for (idx in seq_along(text_inputs)) {
text_input <- text_inputs[idx]
full_prompt <- paste0(
"TASK: Analyze the sentiment of the given text and classify it as **Positive, Neutral, or Negative**.
INSTRUCTIONS:
- Identify the overall sentiment:
- **Positive**: The text expresses enjoyment, excitement, satisfaction, or appreciation.
- **Neutral**: The text states facts without emotion or shows a mix of positive and negative opinions.
- **Negative**: The text expresses frustration, dissatisfaction, or disappointment.
- If a statement lists **favorite things** (e.g., My favorite foods are...), assume **Positive** sentiment unless negative language is present.
- The output should be **only the sentiment label**: `Positive`, `Neutral`, or `Negative`.
EXAMPLES:
1. **Input:** I love pizza, sushi, and burgers!
**Output:** Positive
2. **Input:** My top 3 movies are Inception, The Matrix, and Interstellar.
**Output:** Positive (Because it lists `top` choices)
3. **Input:** Movies I watched last month: Inception, Titanic, The Dark Knight.
**Output:** Neutral (Just listing without opinion)
4. **Input:** I hate horror movies. They're terrible.
**Output:** Negative
===== INPUT TEXT BELOW =====
", text_input
)
print(paste("Processing", idx, "of", length(text_inputs)))
# Ensure we don't exceed 15 requests per minute
current_time <- Sys.time()
if (length(request_times) == 15) {
time_since_first_request <- as.numeric(difftime(current_time, request_times[1], units = "secs"))
if (time_since_first_request < 60) {
wait_time <- 60 - time_since_first_request
print(paste("Rate limit reached. Waiting", round(wait_time, 2), "seconds..."))
Sys.sleep(wait_time)
}
}
# make the request
response <- httr::POST(
url = paste0("https://generativelanguage.googleapis.com/v1beta/models/", model_query),
query = list(key = api_key),
httr::content_type_json(),
encode = "json",
body = list(
contents = list(
parts = list(
list(text = full_prompt) # prompt integrates user input
)),
generationConfig = list(
temperature = temperature,
maxOutputTokens = max_output_tokens
)
)
)
if (response$status_code != 200) {
print(paste("Error - Status Code:", response$status_code))
print(content(response))
stop(paste("Error - ", content(response)$error$message))
}
candidates <- content(response)$candidates
for (candidate in candidates) {
response_text <- gsub("\n", "", candidate$content$parts[[1]]$text)
responses[idx] <- response_text
}
# Record the timestamp of the request
request_times <<- c(request_times, current_time)
if (length(request_times) > 15) {
request_times <<- request_times[-1]
}
}
return(responses)
}
# text_input <- "im getting on borderlands and i will murder you all ,"
# cat("im getting on borderlands and i will murder you all\n➡️", gemini_sentiment_analysis(text_input_1))
# text_input_2 <- "I went to work."
# cat("\nI went to work.\n➡️", gemini_sentiment_analysis(text_input_2))
text_input_3 <- "My 4 fave games are Minecraft. Borderlands 2.Forza horizon 4. Lego star wars"
cat("\nMy 4 fave games are Minecraft. Borderlands 2.Forza horizon 4. Lego star wars\n➡️", gemini_sentiment_analysis(text_input_3))
devtools::check()
devtools::check()
devtools::check()
rm(list = c("gemini_sentiment_analysis"))
devtools::check()
devtools::document()
devtools::document()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
unlink("NAMESPACE")
unlink("man", recursive = TRUE)
devtools::document()
devtools::check()
devtools::check()
unlink("NAMESPACE")  # 删除错误的 NAMESPACE 文件
devtools::document()  # 重新生成 NAMESPACE 和文档
devtools::check()  # 重新检查
devtools::check()
